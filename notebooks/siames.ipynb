{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a2cb98-1736-4a5e-b134-8e7918acd0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f0edc8-49b3-465d-bffa-bffb4b45b3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "margin = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1370c58f-2b2e-4d14-953a-06a67235e2c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4345c03-0750-4158-b5cc-73d31c54a0c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6614cd10-8824-4fac-b38d-1d92e193ed38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 90412 entries, 0 to 90637\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image_url1  90412 non-null  object\n",
      " 1   image_url2  90412 non-null  object\n",
      " 2   is_same     90412 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/prepared_train_with_missed.csv\")\n",
    "df = df[df[\"image_url1\"].notnull() & df[\"image_url2\"].notnull()]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a8dc86-bf67-4935-ba72-10a163608b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "downloaded_files = os.listdir(r\"E:\\datasets\\csc-2023-lun\\train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7083ec58-d27b-46aa-83a3-3e01e9ccadd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_files = set(df[\"image_url1\"]).union(set(df[\"image_url2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93aa30d9-f1ea-4123-a7a9-40bd09ee3209",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed = all_files.difference(downloaded_files)\n",
    "len(missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef991c91-aa04-451d-8c91-ac819458c0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for miss in missed:\n",
    "    df.drop(df[df[\"image_url1\"] == miss].index.values, inplace=True)\n",
    "    df.drop(df[df[\"image_url2\"] == miss].index.values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9fdef1b-d545-440e-8d83-9d2cf1505ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 89925 entries, 0 to 90637\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image_url1  89925 non-null  object\n",
      " 1   image_url2  89925 non-null  object\n",
      " 2   is_same     89925 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9878a4be-a0cc-43e4-9724-7f1dd1bf367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(keras.utils.Sequence):\n",
    "    IMG_W = 128\n",
    "    IMG_H = 128\n",
    "    \n",
    "    def __init__(self, df:pd.DataFrame, images_folder:Path, batch_size:int=32):\n",
    "        self.df = df\n",
    "        self.images_folder = Path(images_folder)\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def get_single_record(self, index):\n",
    "        img_path_1 = self.images_folder / df.iloc[index, df.columns.get_loc(\"image_url1\")]\n",
    "        img_path_2 = self.images_folder / df.iloc[index, df.columns.get_loc(\"image_url2\")]\n",
    "        \n",
    "        image_1 = cv2.imread(str(img_path_1))\n",
    "        image_2 = cv2.imread(str(img_path_2))\n",
    "        assert image_1 is not None and image_2 is not None\n",
    "        \n",
    "        image_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB)\n",
    "        image_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        image_1 = cv2.resize(image_1, (self.IMG_W, self.IMG_H)).astype(np.float32)\n",
    "        image_2 = cv2.resize(image_2, (self.IMG_W, self.IMG_H)).astype(np.float32)\n",
    "        \n",
    "        image_1 /= 255.\n",
    "        image_2 /= 255.\n",
    "        \n",
    "        target = df.iloc[index, df.columns.get_loc(\"is_same\")]\n",
    "        \n",
    "        return tf.convert_to_tensor(image_1), tf.convert_to_tensor(image_2), target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x_batch_1 = []\n",
    "        x_batch_2 = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(index*batch_size, (index+1)*batch_size):\n",
    "            img_1, img_2, label = self.get_single_record(i)\n",
    "            x_batch_1.append(img_1)\n",
    "            x_batch_2.append(img_2)\n",
    "            labels.append(label)\n",
    "        \n",
    "        return [tf.convert_to_tensor(x_batch_1, dtype=float), tf.convert_to_tensor(x_batch_2, dtype=float)], \\\n",
    "                tf.convert_to_tensor(labels, dtype=float)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d5b058-dfae-4a9e-9f44-360d31992b24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89925, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04af4b6c-55c1-4e06-be2c-c98cbca50fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = df.iloc[:80000]\n",
    "valid_df = df.iloc[80000:]\n",
    "\n",
    "train_loader = DataLoader(train_df, r\"E:\\datasets\\csc-2023-lun\\train\", batch_size=16)\n",
    "valid_loader = DataLoader(valid_df, r\"E:\\datasets\\csc-2023-lun\\train\", batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c676e35d-deeb-4e16-bd22-79615b88d6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25603"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_df[\"is_same\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58b82afe-451a-42e2-8b9e-6c2caea62ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54397"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_df[\"is_same\"] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6eaf3-4c0b-4014-b345-01ed1846b91c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b4a8aff-0147-4e88-9cc4-79924f971d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects:List):\n",
    "    v1, v2 = vects\n",
    "    \n",
    "    sum_squared = tf.math.reduce_sum(tf.math.square(v1 - v2), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_squared, tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0678140-65d8-47df-89dc-b4acbf4bc4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[5.196152]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance((\n",
    "    tf.constant([[1, 2, 3]], dtype=float),\n",
    "    tf.constant([[4, 5, 6]], dtype=float)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b47765d3-dab6-4421-9107-3f8b403279e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_embedding_model(input_shape, embeddings_dim):\n",
    "    inp = keras.layers.Input(input_shape)\n",
    "    \n",
    "    x = keras.layers.Conv2D(filters=5, kernel_size=5, activation=\"tanh\")(inp)\n",
    "    x = keras.layers.AveragePooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(filters=16, kernel_size=5, activation=\"tanh\")(x)\n",
    "    x = keras.layers.AveragePooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(filters=32, kernel_size=5, activation=\"tanh\")(x)\n",
    "    x = keras.layers.AveragePooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    embeddings = keras.layers.Dense(embeddings_dim, activation=\"tanh\")(x)\n",
    "    \n",
    "    embedding_net = keras.models.Model(inp, embeddings, name=\"embeddings_backbone\")\n",
    "    return embedding_net\n",
    "\n",
    "def build_model(input_shape, embedding_dim=128):\n",
    "    embedding_net = build_embedding_model(input_shape, embedding_dim)\n",
    "    \n",
    "    input_1 = keras.layers.Input(input_shape, name=\"input_1\")\n",
    "    input_2 = keras.layers.Input(input_shape, name=\"input_2\")\n",
    "\n",
    "    tower_1 = embedding_net(input_1)\n",
    "    tower_2 = embedding_net(input_2)\n",
    "    \n",
    "    merge_layer = keras.layers.Lambda(euclidean_distance)([tower_1, tower_2])\n",
    "    bn_layer = keras.layers.Normalization()(merge_layer)\n",
    "    out = keras.layers.Dense(1, activation=\"sigmoid\")(bn_layer)\n",
    "    \n",
    "    siamese = keras.models.Model(inputs=[input_1, input_2], outputs=out)\n",
    "    return siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7851ad7-266c-40e4-a723-cc720f819e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embeddings_backbone\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 124, 124, 5)       380       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 62, 62, 5)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 58, 58, 16)        2016      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 29, 29, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 25, 25, 32)        12832     \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 12, 12, 32)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 4608)             18432     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2359808   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,393,468\n",
      "Trainable params: 2,384,252\n",
      "Non-trainable params: 9,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embeddings_model = build_embedding_model((128, 128, 3), 512)\n",
    "embeddings_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36f5c194-2aa2-47cc-bd42-6fc1a9aa0112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Loss(keras.losses.Loss):\n",
    "    def __init__(self, margin:int=1):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        pred_squared = tf.math.square(y_pred)\n",
    "        margin_squared = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * pred_squared + (y_true) * margin_squared\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3222c59-c697-4a5d-bd3e-e8af56581e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_model((128, 128, 3), 512)\n",
    "model.compile(\n",
    "    loss=Loss(margin=margin),\n",
    "    optimizer=\"Adam\",\n",
    "    metrics=[keras.metrics.Accuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf079ceb-3aca-4f2e-8222-60f35d35e998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embeddings_backbone (Functiona  (None, 512)         2393468     ['input_1[0][0]',                \n",
      " l)                                                               'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['embeddings_backbone[0][0]',    \n",
      "                                                                  'embeddings_backbone[1][0]']    \n",
      "                                                                                                  \n",
      " normalization (Normalization)  (None, 1)            3           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            2           ['normalization[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,393,473\n",
      "Trainable params: 2,384,254\n",
      "Non-trainable params: 9,219\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8634c93-fca9-4eab-94d0-6dd0998c0142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\"models/checkpoints/simple-siam-checkpoint-best.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb9c32-5b3b-45ec-a08c-8d1938805a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 7163s 1s/step - loss: 0.0820 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 7560s 2s/step - loss: 0.0190 - accuracy: 0.0000e+00 - val_loss: 0.2760 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 7528s 2s/step - loss: 0.0126 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 9313s 2s/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 9300s 2s/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "2698/5000 [===============>..............] - ETA: 1:07:00 - loss: 0.0080 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_loader,\n",
    "    validation_data=valid_loader,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c3c5ec-8b06-47ec-a995-e1ac9100d98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd664cf4-8377-40de-8232-eede5157f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/simple-siam-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ff0a0-bd39-4888-a450-9efb6432f24b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plt_metric(history, metric, title, has_valid=True):\n",
    "    try:\n",
    "        history = history.history\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    plt.plot(history[metric])\n",
    "    if has_valid:\n",
    "        plt.plot(history[\"val_\" + metric])\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n",
    "\n",
    "plt_metric(history=history, metric=\"loss\", title=\"Contrastive Loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f2230-c8de-4fab-a3ae-2fdf7f2c5f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6581ef-ffbb-418f-ab75-b386c0b94e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
